{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import REFLACXWithClinicalDataset, RecordPoint\n",
    "from model.xami import XAMIMultiModalSum\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the GPU is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "# setting up the device\n",
    "device = 'cuda' if use_gpu else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "reflacx_dataset = REFLACXWithClinicalDataset()\n",
    "\n",
    "# prepare the model\n",
    "xami_mutlimodal = XAMIMultiModalSum(reflacx_dataset, device)\n",
    "xami_mutlimodal = xami_mutlimodal.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare learning parameters\n",
    "\n",
    "lr = 0.0001\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, xami_mutlimodal.parameters()), lr= lr, weight_decay= 0)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, threshold=0.001, factor=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the dataset\n",
    "\n",
    "train_dataset_len = int(len(reflacx_dataset) * .8)\n",
    "test_dataset_len = int(len(reflacx_dataset) * .1)\n",
    "val_dataset_len = len(reflacx_dataset) - (train_dataset_len + test_dataset_len)\n",
    "\n",
    "\n",
    "# how does it seperate tthem?\n",
    "(\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    test_dataset\n",
    ") = torch.utils.data.random_split(\n",
    "    dataset= reflacx_dataset,\n",
    "    lengths = [train_dataset_len, val_dataset_len, test_dataset_len],\n",
    "    generator = torch.Generator().manual_seed(\n",
    "        123\n",
    "    )\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    collate_fn= reflacx_dataset.train_collate_fn\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    collate_fn= reflacx_dataset.test_collate_fn\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size= batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn= reflacx_dataset.test_collate_fn\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, device):\n",
    "    image, clinical_data, label = data\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "    clinical_numerical_data, clinical_categorical_data = clinical_data\n",
    "    clinical_numerical_data = clinical_numerical_data.to(device)\n",
    "\n",
    "    for col in clinical_categorical_data.keys():\n",
    "        clinical_categorical_data[col] = clinical_categorical_data[col].to(device)\n",
    "\n",
    "    clinical_data = (clinical_numerical_data, clinical_categorical_data)\n",
    "\n",
    "    image = Variable(image, requires_grad=False)\n",
    "    label = Variable(label, requires_grad=False)\n",
    "\n",
    "    clinical_numerical_data, clinical_categorical_data = clinical_data\n",
    "    clinical_numerical_data = Variable(clinical_numerical_data, requires_grad=False)\n",
    "\n",
    "    for col in clinical_categorical_data.keys():\n",
    "        clinical_categorical_data[col] = Variable(clinical_categorical_data[col], requires_grad= False)\n",
    "\n",
    "    clinical_data = (clinical_numerical_data, clinical_categorical_data)\n",
    "\n",
    "    return image, clinical_data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement test 1 epoch here\n",
    "def train_epoch(epoch, model, dataloader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    batch_losses = []\n",
    "    batch_accuracy = []\n",
    "    batch_auc = []\n",
    "\n",
    "    epoch = 1\n",
    "\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        image, clinical_data, label = transform_data(data, device, train=True)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image, clinical_data)\n",
    "        loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Epoch: {:d} Batch:  ({:d}) Train Loss: {:.4f}\".format(\n",
    "            epoch, batch_idx, loss.item()))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        # want accuracy here.\n",
    "        batch_accuracy.append(\n",
    "            accuracy_score(\n",
    "                label.detach().cpu().numpy().flatten(), (outputs.detach().cpu().numpy() > 0.5).astype('int64').flatten())\n",
    "        )\n",
    "        batch_auc.append(roc_auc_score(label.detach().cpu().numpy(\n",
    "        ).flatten(), outputs.detach().cpu().numpy().flatten()))\n",
    "\n",
    "\n",
    "    train_loss = np.mean(batch_losses)\n",
    "    train_acc = np.mean(batch_accuracy)\n",
    "    train_auc = np.mean(batch_auc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch} | Loss: {train_loss:.2f} | ACC: {train_acc*100:.2f}% | AUC: {train_auc:.2f}\")\n",
    "\n",
    "    return train_loss, train_acc, train_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement train 1 epoch here\n",
    "def test_epoch(epoch, model, dataloader, loss_fn, ):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    batch_losses = []\n",
    "    batch_accuracy = []\n",
    "    batch_auc = []\n",
    "\n",
    "    epoch = 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(dataloader):\n",
    "            image, clinical_data, label = transform_data(\n",
    "                data, device, train=False)\n",
    "            outputs = model(image, clinical_data)\n",
    "            loss = loss_fn(outputs, label)\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            # want accuracy here.\n",
    "            batch_accuracy.append(\n",
    "                accuracy_score(\n",
    "                    label.detach().cpu().numpy().flatten(), (outputs.detach().cpu().numpy() > 0.5).astype('int64').flatten())\n",
    "            )\n",
    "            batch_auc.append(roc_auc_score(label.detach().cpu().numpy(\n",
    "            ).flatten(), outputs.detach().cpu().numpy().flatten()))\n",
    "\n",
    "            print(\"Epoch: {:d} Batch:  ({:d}) Test Loss: {:.4f}\".format(\n",
    "                epoch, batch_idx, loss.item()))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "  \n",
    "\n",
    "    test_loss = np.mean(batch_losses)\n",
    "    test_acc = np.mean(batch_accuracy)\n",
    "    test_auc = np.mean(batch_auc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch} | Loss: {test_loss:.2f} | ACC: {test_acc*100:.2f}% | AUC: {test_auc:.2f}\")\n",
    "\n",
    "    return test_loss, test_acc, test_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "Epoch: 1 Batch:  (0) Train Loss: 0.9523\n",
      "Epoch: 1 Batch:  (1) Train Loss: 0.9579\n",
      "Epoch: 1 Batch:  (2) Train Loss: 0.9647\n",
      "Epoch: 1 Batch:  (3) Train Loss: 0.9411\n",
      "Epoch: 1 Batch:  (4) Train Loss: 0.9508\n",
      "Epoch 1 | Loss: 0.95 | ACC: 47.50% | AUC: 0.62\n",
      "Epoch: 1 Batch:  (0) Test Loss: 0.9426\n",
      "Epoch: 1 Batch:  (1) Test Loss: 0.9357\n",
      "Epoch: 1 Batch:  (2) Test Loss: 0.9081\n",
      "Epoch 1 | Loss: 0.93 | ACC: 52.40% | AUC: 0.64\n",
      "Best Validation Loss: 0.9288\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "num_epochs = 2\n",
    "best_model_wts, best_loss = xami_mutlimodal.state_dict(), float(\"inf\")\n",
    "counter = 0\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    train_loss, train_acc, _ = train_epoch(epoch, xami_mutlimodal, dataloader=train_dataloader,\n",
    "                loss_fn=loss_fn, optimizer=optimizer)\n",
    "    val_loss, val_acc, _ = test_epoch(epoch, xami_mutlimodal,\n",
    "                                dataloader=val_dataloader, loss_fn=loss_fn,)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if (val_loss < best_loss):\n",
    "\n",
    "        best_loss = val_loss\n",
    "        best_model_wts = xami_mutlimodal.state_dict()\n",
    "        counter = 0\n",
    "    \n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter > 3:\n",
    "            break\n",
    "\n",
    "    torch.save(best_model_wts, os.path.join(\"saved_models\", f\"{val_loss:.4f}_{str(datetime.now())}\".replace(\":\",\"_\")))\n",
    "\n",
    "print(f\"Best Validation Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a402e4e4296f2d4bed1c089fb7c7e828933dcbfe50698b381e393c052eea855"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
